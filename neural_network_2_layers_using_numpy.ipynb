{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_network_2 layers_using_numpy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8GhvClYtDxeYO4BLrT7db",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palVikram/Machine-Learning-using-Python/blob/master/neural_network_2_layers_using_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZJLRBxX3Idsh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## http://archive.ics.uci.edu/ml/datasets/banknote+authentication#\n",
        "### download data set from the above link "
      ],
      "metadata": {
        "id": "kVvldfrhS8Jq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=np.genfromtxt('/content/data_banknote_authentication.txt',delimiter=',')"
      ],
      "metadata": {
        "id": "Qb-6F0uZOiK6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[:,:4]\n",
        "y = df[:, 4]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8z_RDG1OtLU",
        "outputId": "6b6419fb-cf06-42cb-cec5-f7d698abaebe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
              "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
              "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
              "       ...,\n",
              "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
              "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
              "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.T\n",
        "y_train = y_train.reshape(1, y_train.shape[0])\n",
        "\n",
        "X_test = X_test.T\n",
        "y_test = y_test.reshape(1, y_test.shape[0])"
      ],
      "metadata": {
        "id": "fE3P_uuROR2v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network_model(X, Y, hidden_unit, num_iterations = 1000):\n",
        "\n",
        "    input_unit = X.shape[0] # size of input layer\n",
        "    hidden_unit = 4 #hidden layer of size 4\n",
        "    output_unit = Y.shape[0] # size of output layer\n",
        "\n",
        "    W0 = np.random.randn(hidden_unit, input_unit)*0.01\n",
        "    b0 = np.zeros((hidden_unit, 1))\n",
        "\n",
        "    W1 = np.random.randn(hidden_unit, input_unit)*0.01\n",
        "    b1 = np.zeros((hidden_unit, 1))\n",
        "    \n",
        "    W2 = np.random.randn(output_unit, hidden_unit)*0.01\n",
        "    b2 = np.zeros((output_unit, 1))\n",
        "   \n",
        "    learning_rate = 0.01\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        ### forward propagation\n",
        "        Z0 = np.dot(W0, X) + b0\n",
        "        A0 = np.tanh(Z0)\n",
        "\n",
        "        Z1 = np.dot(W1, Z0) + b1\n",
        "        A1 = np.tanh(Z1)\n",
        "\n",
        "        Z2 = np.dot(W2, A1) + b2\n",
        "        A2 = 1/(1+np.exp(-Z2))\n",
        "\n",
        "        ### cross entropy cost\n",
        "        m = Y.shape[1] \n",
        "        # Compute the cross-entropy cost\n",
        "        logprobs = np.multiply(np.log(A2), Y) + np.multiply((1-Y), np.log(1 - A2))\n",
        "        cost = - np.sum(logprobs) / m\n",
        "        cost = float(np.squeeze(cost))\n",
        "\n",
        "        ### backward propagaation function\n",
        "        dZ2 = A2-Y\n",
        "        dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
        "        db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)  \n",
        "        \n",
        "        dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
        "        dW1 = (1/m) * np.dot(dZ1, A0.T) \n",
        "        db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "        dZ0 = np.multiply(np.dot(W1.T, dZ1), 1 - np.power(A0, 2))\n",
        "        dW0 = (1/m) * np.dot(dZ0, X.T) \n",
        "        db0 = (1/m)*np.sum(dZ0, axis=1, keepdims=True)\n",
        "\n",
        "        ### grad update \n",
        "        W0 = W0 - learning_rate * dW0\n",
        "        b0 = b0 - learning_rate * db0\n",
        "\n",
        "        W1 = W1 - learning_rate * dW1\n",
        "        b1 = b1 - learning_rate * db1\n",
        "\n",
        "        W2 = W2 - learning_rate * dW2\n",
        "        b2 = b2 - learning_rate * db2\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "    return W0,W1,W2,b0,b1,b2\n",
        "\n",
        "W0,W1,W2,b0,b1,b2 = neural_network_model(X_train, y_train, 4, num_iterations=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iNqHrzpIzk3",
        "outputId": "651891c1-6bfb-4388-ea64-a86a468658be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.693154\n",
            "Cost after iteration 5: 0.692977\n",
            "Cost after iteration 10: 0.692805\n",
            "Cost after iteration 15: 0.692638\n",
            "Cost after iteration 20: 0.692474\n",
            "Cost after iteration 25: 0.692314\n",
            "Cost after iteration 30: 0.692159\n",
            "Cost after iteration 35: 0.692007\n",
            "Cost after iteration 40: 0.691859\n",
            "Cost after iteration 45: 0.691715\n",
            "Cost after iteration 50: 0.691574\n",
            "Cost after iteration 55: 0.691436\n",
            "Cost after iteration 60: 0.691303\n",
            "Cost after iteration 65: 0.691172\n",
            "Cost after iteration 70: 0.691045\n",
            "Cost after iteration 75: 0.690920\n",
            "Cost after iteration 80: 0.690799\n",
            "Cost after iteration 85: 0.690681\n",
            "Cost after iteration 90: 0.690566\n",
            "Cost after iteration 95: 0.690453\n",
            "Cost after iteration 100: 0.690344\n",
            "Cost after iteration 105: 0.690237\n",
            "Cost after iteration 110: 0.690133\n",
            "Cost after iteration 115: 0.690031\n",
            "Cost after iteration 120: 0.689932\n",
            "Cost after iteration 125: 0.689835\n",
            "Cost after iteration 130: 0.689741\n",
            "Cost after iteration 135: 0.689649\n",
            "Cost after iteration 140: 0.689559\n",
            "Cost after iteration 145: 0.689471\n",
            "Cost after iteration 150: 0.689386\n",
            "Cost after iteration 155: 0.689303\n",
            "Cost after iteration 160: 0.689221\n",
            "Cost after iteration 165: 0.689142\n",
            "Cost after iteration 170: 0.689065\n",
            "Cost after iteration 175: 0.688990\n",
            "Cost after iteration 180: 0.688916\n",
            "Cost after iteration 185: 0.688844\n",
            "Cost after iteration 190: 0.688775\n",
            "Cost after iteration 195: 0.688706\n",
            "Cost after iteration 200: 0.688640\n",
            "Cost after iteration 205: 0.688575\n",
            "Cost after iteration 210: 0.688512\n",
            "Cost after iteration 215: 0.688450\n",
            "Cost after iteration 220: 0.688390\n",
            "Cost after iteration 225: 0.688331\n",
            "Cost after iteration 230: 0.688274\n",
            "Cost after iteration 235: 0.688218\n",
            "Cost after iteration 240: 0.688164\n",
            "Cost after iteration 245: 0.688110\n",
            "Cost after iteration 250: 0.688059\n",
            "Cost after iteration 255: 0.688008\n",
            "Cost after iteration 260: 0.687959\n",
            "Cost after iteration 265: 0.687911\n",
            "Cost after iteration 270: 0.687864\n",
            "Cost after iteration 275: 0.687818\n",
            "Cost after iteration 280: 0.687774\n",
            "Cost after iteration 285: 0.687730\n",
            "Cost after iteration 290: 0.687688\n",
            "Cost after iteration 295: 0.687646\n",
            "Cost after iteration 300: 0.687606\n",
            "Cost after iteration 305: 0.687566\n",
            "Cost after iteration 310: 0.687528\n",
            "Cost after iteration 315: 0.687491\n",
            "Cost after iteration 320: 0.687454\n",
            "Cost after iteration 325: 0.687418\n",
            "Cost after iteration 330: 0.687384\n",
            "Cost after iteration 335: 0.687350\n",
            "Cost after iteration 340: 0.687317\n",
            "Cost after iteration 345: 0.687284\n",
            "Cost after iteration 350: 0.687253\n",
            "Cost after iteration 355: 0.687222\n",
            "Cost after iteration 360: 0.687192\n",
            "Cost after iteration 365: 0.687163\n",
            "Cost after iteration 370: 0.687134\n",
            "Cost after iteration 375: 0.687107\n",
            "Cost after iteration 380: 0.687080\n",
            "Cost after iteration 385: 0.687053\n",
            "Cost after iteration 390: 0.687027\n",
            "Cost after iteration 395: 0.687002\n",
            "Cost after iteration 400: 0.686978\n",
            "Cost after iteration 405: 0.686954\n",
            "Cost after iteration 410: 0.686930\n",
            "Cost after iteration 415: 0.686908\n",
            "Cost after iteration 420: 0.686885\n",
            "Cost after iteration 425: 0.686864\n",
            "Cost after iteration 430: 0.686843\n",
            "Cost after iteration 435: 0.686822\n",
            "Cost after iteration 440: 0.686802\n",
            "Cost after iteration 445: 0.686782\n",
            "Cost after iteration 450: 0.686763\n",
            "Cost after iteration 455: 0.686744\n",
            "Cost after iteration 460: 0.686726\n",
            "Cost after iteration 465: 0.686708\n",
            "Cost after iteration 470: 0.686691\n",
            "Cost after iteration 475: 0.686674\n",
            "Cost after iteration 480: 0.686658\n",
            "Cost after iteration 485: 0.686642\n",
            "Cost after iteration 490: 0.686626\n",
            "Cost after iteration 495: 0.686611\n",
            "Cost after iteration 500: 0.686596\n",
            "Cost after iteration 505: 0.686581\n",
            "Cost after iteration 510: 0.686567\n",
            "Cost after iteration 515: 0.686553\n",
            "Cost after iteration 520: 0.686539\n",
            "Cost after iteration 525: 0.686526\n",
            "Cost after iteration 530: 0.686513\n",
            "Cost after iteration 535: 0.686501\n",
            "Cost after iteration 540: 0.686489\n",
            "Cost after iteration 545: 0.686477\n",
            "Cost after iteration 550: 0.686465\n",
            "Cost after iteration 555: 0.686454\n",
            "Cost after iteration 560: 0.686442\n",
            "Cost after iteration 565: 0.686432\n",
            "Cost after iteration 570: 0.686421\n",
            "Cost after iteration 575: 0.686411\n",
            "Cost after iteration 580: 0.686401\n",
            "Cost after iteration 585: 0.686391\n",
            "Cost after iteration 590: 0.686381\n",
            "Cost after iteration 595: 0.686372\n",
            "Cost after iteration 600: 0.686363\n",
            "Cost after iteration 605: 0.686354\n",
            "Cost after iteration 610: 0.686345\n",
            "Cost after iteration 615: 0.686337\n",
            "Cost after iteration 620: 0.686329\n",
            "Cost after iteration 625: 0.686321\n",
            "Cost after iteration 630: 0.686313\n",
            "Cost after iteration 635: 0.686305\n",
            "Cost after iteration 640: 0.686298\n",
            "Cost after iteration 645: 0.686290\n",
            "Cost after iteration 650: 0.686283\n",
            "Cost after iteration 655: 0.686276\n",
            "Cost after iteration 660: 0.686270\n",
            "Cost after iteration 665: 0.686263\n",
            "Cost after iteration 670: 0.686257\n",
            "Cost after iteration 675: 0.686250\n",
            "Cost after iteration 680: 0.686244\n",
            "Cost after iteration 685: 0.686238\n",
            "Cost after iteration 690: 0.686232\n",
            "Cost after iteration 695: 0.686227\n",
            "Cost after iteration 700: 0.686221\n",
            "Cost after iteration 705: 0.686216\n",
            "Cost after iteration 710: 0.686210\n",
            "Cost after iteration 715: 0.686205\n",
            "Cost after iteration 720: 0.686200\n",
            "Cost after iteration 725: 0.686195\n",
            "Cost after iteration 730: 0.686190\n",
            "Cost after iteration 735: 0.686186\n",
            "Cost after iteration 740: 0.686181\n",
            "Cost after iteration 745: 0.686177\n",
            "Cost after iteration 750: 0.686172\n",
            "Cost after iteration 755: 0.686168\n",
            "Cost after iteration 760: 0.686164\n",
            "Cost after iteration 765: 0.686160\n",
            "Cost after iteration 770: 0.686156\n",
            "Cost after iteration 775: 0.686152\n",
            "Cost after iteration 780: 0.686149\n",
            "Cost after iteration 785: 0.686145\n",
            "Cost after iteration 790: 0.686141\n",
            "Cost after iteration 795: 0.686138\n",
            "Cost after iteration 800: 0.686134\n",
            "Cost after iteration 805: 0.686131\n",
            "Cost after iteration 810: 0.686128\n",
            "Cost after iteration 815: 0.686125\n",
            "Cost after iteration 820: 0.686122\n",
            "Cost after iteration 825: 0.686119\n",
            "Cost after iteration 830: 0.686116\n",
            "Cost after iteration 835: 0.686113\n",
            "Cost after iteration 840: 0.686110\n",
            "Cost after iteration 845: 0.686107\n",
            "Cost after iteration 850: 0.686105\n",
            "Cost after iteration 855: 0.686102\n",
            "Cost after iteration 860: 0.686100\n",
            "Cost after iteration 865: 0.686097\n",
            "Cost after iteration 870: 0.686095\n",
            "Cost after iteration 875: 0.686092\n",
            "Cost after iteration 880: 0.686090\n",
            "Cost after iteration 885: 0.686088\n",
            "Cost after iteration 890: 0.686086\n",
            "Cost after iteration 895: 0.686083\n",
            "Cost after iteration 900: 0.686081\n",
            "Cost after iteration 905: 0.686079\n",
            "Cost after iteration 910: 0.686077\n",
            "Cost after iteration 915: 0.686075\n",
            "Cost after iteration 920: 0.686073\n",
            "Cost after iteration 925: 0.686072\n",
            "Cost after iteration 930: 0.686070\n",
            "Cost after iteration 935: 0.686068\n",
            "Cost after iteration 940: 0.686066\n",
            "Cost after iteration 945: 0.686065\n",
            "Cost after iteration 950: 0.686063\n",
            "Cost after iteration 955: 0.686061\n",
            "Cost after iteration 960: 0.686060\n",
            "Cost after iteration 965: 0.686058\n",
            "Cost after iteration 970: 0.686057\n",
            "Cost after iteration 975: 0.686055\n",
            "Cost after iteration 980: 0.686054\n",
            "Cost after iteration 985: 0.686053\n",
            "Cost after iteration 990: 0.686051\n",
            "Cost after iteration 995: 0.686050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X,W0,W1,W2,b0,b1,b2):\n",
        "        ### forward propagation\n",
        "        Z0 = np.dot(W0, X) + b0\n",
        "        A0 = np.tanh(Z0)\n",
        "\n",
        "        Z1 = np.dot(W1, Z0) + b1\n",
        "        A1 = np.tanh(Z1)\n",
        "\n",
        "        Z2 = np.dot(W2, A1) + b2\n",
        "        A2 = 1/(1+np.exp(-Z2))\n",
        "\n",
        "        return A2\n"
      ],
      "metadata": {
        "id": "iH0GPL7qQVhr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(W0,W1,W2,b0,b1,b2, X):\n",
        "    A2 = forward_propagation(X,W0,W1,W2,b0,b1,b2)\n",
        "    predictions = np.round(A2)\n",
        "    \n",
        "    return predictions"
      ],
      "metadata": {
        "id": "c_XuHDLAI30r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = prediction(W0,W1,W2,b0,b1,b2, X_train)\n",
        "print ('Accuracy Train: %d' % float((np.dot(y_train, predictions.T) + np.dot(1 - y_train, 1 - predictions.T))/float(y_train.size)*100) + '%')\n",
        "\n",
        "predictions = prediction(W0,W1,W2,b0,b1,b2, X_test)\n",
        "print ('Accuracy Test: %d' % float((np.dot(y_test, predictions.T) + np.dot(1 - y_test, 1 - predictions.T))/float(y_test.size)*100) + '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt0Lq3lzI7b3",
        "outputId": "57953d2e-d64b-4fee-a9c1-93c9c86cbfde"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 55%\n",
            "Accuracy Test: 53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HsX6SjGXQ1Ot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}